{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1><center>PyTorch Introduction</center></h1>"
      ],
      "metadata": {
        "id": "rOhddYaBUvsj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br> A deep learning framework is an interface, library or a tool which allows us to build deep learning models more easily and quickly, without getting into the details of underlying algorithms. They provide a clear and concise way for defining models using a collection of pre-built and optimized components. PyTorch, TensorFlow, Keras are examples for commonly used deep learning frameworks.\n",
        "\n",
        "\n",
        "<br><br>A standard deeplearning framework can:\n",
        "<ul><li>Build and operate computational graphs (More on this to follow)</li>\n",
        "    <li>Perform forward and back propagation</li>\n",
        "    <li>Parallelize on GPU</li>\n",
        "    <li>Provide standard architecture and other widely used primitives</li>\n",
        "    </ul>\n",
        "    \n",
        "Why Pytorch?\n",
        "\n",
        "<ul><li>Dynamic computational graph</li>\n",
        "    <li>Memory efficient Usage</li>\n",
        "    <li>Developer friendly: easy to implement, debug</li>\n",
        "    <li>Tensor computation with strong gpu acceleration</li>\n",
        "    </ul>\n",
        "\n",
        "<h2>Basics of PyTorch</h2>\n",
        "\n",
        "<h3>Building Block #1 : Tensors</h3>\n",
        "\n",
        "If you’ve ever done machine learning in python, you’ve probably come across NumPy. The reason why we use Numpy is because it’s much faster than Python lists at doing matrix ops. Why? Because it does most of the heavy lifting in C.\n",
        "\n",
        "But, in case of training deep neural networks, NumPy arrays simply don’t cut it. Code written using NumPy arrays alone would take months to train some of the state of the art networks. This is where Tensors come into play. PyTorch provides us with a data structure called Tensors, which is very similar to NumPy’s ndarray. But unlike the latter, <b>tensors can tap into resources of a GPU to significantly speed up matrix operations</b>."
      ],
      "metadata": {
        "id": "uOOP0znvU0rx"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "R10gTaB_a4RI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f06479a1-43a7-4830-9ce8-82a0f2b0ec98"
      },
      "source": [
        "!pip3 install torch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqeJGkJ69EJP",
        "outputId": "298c54f7-7fea-4b47-a741-87d5d1111ad0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yQyeW447oPX"
      },
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0m8NquV9AkO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9853474d-5f89-420e-a41f-48d29c486ef2"
      },
      "source": [
        "print(torch.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.3.1+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3Gvc41f_sZX"
      },
      "source": [
        "#**Tensor**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibPI9LWv3n1I"
      },
      "source": [
        "###Initializing a tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boujstAO_tez",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8de25b9f-82eb-4f7b-9d54-a05325737762"
      },
      "source": [
        "# Initializing a tensor\n",
        "a = torch.Tensor([1, 2,3])\n",
        "print(a.size())\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3])\n",
            "tensor([1., 2., 3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvRbCmeeA8-4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9f3ee13c-8059-4bc7-cd0d-d3ec69662666"
      },
      "source": [
        "a.type()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'torch.FloatTensor'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaOUoWCIgzkP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "953a3796-c064-4759-8c89-a94a2ed59e50"
      },
      "source": [
        "t = torch.Tensor([[1, 2, 3], [4, 5, 6]])\n",
        "print(t)\n",
        "print(t.t())\n",
        "print(t.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "tensor([[1., 4.],\n",
            "        [2., 5.],\n",
            "        [3., 6.]])\n",
            "torch.Size([2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erGJUPD_3wnf"
      },
      "source": [
        "### Creating a scalar tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntQetme0JVrG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bf82e67-0946-434d-efc3-e65d1790d114"
      },
      "source": [
        "a = torch.tensor(20)\n",
        "print(a)\n",
        "print(a.size())\n",
        "print(a.type())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(20)\n",
            "torch.Size([])\n",
            "torch.LongTensor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVe0vlBf33Rk"
      },
      "source": [
        "###Converting pytorch tensor to scalar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YG-0BGYS31NC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1de940d0-334a-4a5a-d4f1-3020e2945c5b"
      },
      "source": [
        "print(a.item())\n",
        "print(type(a.item()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n",
            "<class 'int'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkaFxLkq4BU1"
      },
      "source": [
        "###Creating a float tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weOySs2yCdZr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "560e7a6e-e6a7-4042-e14b-f64397913e0b"
      },
      "source": [
        "a = torch.tensor([2.0,3])\n",
        "a.type()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'torch.FloatTensor'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4xjFsBB4E7V"
      },
      "source": [
        "###Providing the data type while creating the tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLNhdgLACwfN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0fdb896f-fbe6-446a-cbad-066667248980"
      },
      "source": [
        "a = torch.tensor([2,3],dtype=torch.int32)\n",
        "a.type()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'torch.IntTensor'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shuIdBhA4LAX"
      },
      "source": [
        "###Just like numpy, creating a tensor by copying another tensor results, pointing to same memory location\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtMzpVhkDhQ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27e76d40-cbec-413a-bc6c-ee97a11379e9"
      },
      "source": [
        "a = torch.tensor([2.0, 3])\n",
        "b = a\n",
        "c=a.clone()\n",
        "b[0] = 11\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([11.,  3.])\n",
            "tensor([11.,  3.])\n",
            "tensor([2., 3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymR9skNc4OfB"
      },
      "source": [
        "###2D tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZ2VIKmgEW-u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2fe9322-1775-4233-a4eb-d4487dc8e36b"
      },
      "source": [
        "a = torch.tensor([[1,2],[3,4]])\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeWWw8pd418E"
      },
      "source": [
        "###Creating and initializing a tensor with random values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-MUv5zpFRoq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6502c20-b01f-4aa2-f70b-120faeed9034"
      },
      "source": [
        "a = torch.rand(3,4)\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1166, 0.9067, 0.9322, 0.1386],\n",
            "        [0.4537, 0.1143, 0.8421, 0.8472],\n",
            "        [0.3904, 0.6540, 0.0512, 0.9952]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2fOgMay455N"
      },
      "source": [
        "###Creating and initializing a float tensor with zeros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9_68kZ8F7Ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "895e89ad-09b4-4432-dc2a-579084a7c5e3"
      },
      "source": [
        "a = torch.zeros((4,5), dtype=torch.float32)\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vffsQ4344974"
      },
      "source": [
        "###Creating an Identity tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xBd2Fu1GqVv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd63712d-fc4f-4828-9d37-fc6e9552f1fa"
      },
      "source": [
        "a = torch.eye(4,4)\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 0., 0.],\n",
            "        [0., 1., 0., 0.],\n",
            "        [0., 0., 1., 0.],\n",
            "        [0., 0., 0., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZ33siBjFGrN"
      },
      "source": [
        "#**Tensor Operations**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4YECoP35BQm"
      },
      "source": [
        "###Addition of two tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahpXC1TQFJ5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1a4457c-9234-432b-e2a0-33e0a2698f2f"
      },
      "source": [
        "x = torch.rand(3,3)\n",
        "y = torch.rand(3,3)\n",
        "z = x+y\n",
        "print(z)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8764, 0.7288, 0.8337],\n",
            "        [1.2990, 1.3119, 0.5343],\n",
            "        [0.2397, 0.4752, 1.9146]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncyqH1wm5G50"
      },
      "source": [
        "###Addition of two tensor (alternative)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgIqg4g4IfVe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8695d1c-5fe6-41b1-cadb-c579a1e7380a"
      },
      "source": [
        "z = x.add(y)\n",
        "print(z)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8764, 0.7288, 0.8337],\n",
            "        [1.2990, 1.3119, 0.5343],\n",
            "        [0.2397, 0.4752, 1.9146]])\n",
            "tensor([[0.0111, 0.0831, 0.7757],\n",
            "        [0.3303, 0.7507, 0.0851],\n",
            "        [0.1100, 0.0687, 0.9490]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIN8u1A_5OlI"
      },
      "source": [
        "###Inplace addition of two tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOqXYTkgIjfp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5062767e-cb42-4f31-8dcc-f5cb4efda1f3"
      },
      "source": [
        "print(x)\n",
        "\n",
        "x.add_(y)\n",
        "\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0111, 0.0831, 0.7757],\n",
            "        [0.3303, 0.7507, 0.0851],\n",
            "        [0.1100, 0.0687, 0.9490]])\n",
            "tensor([[0.8764, 0.7288, 0.8337],\n",
            "        [1.2990, 1.3119, 0.5343],\n",
            "        [0.2397, 0.4752, 1.9146]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kI1TfG2B5lBP"
      },
      "source": [
        "###Element wise multiplication"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IxgHBbzIuDF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "772807fa-2c32-4fc6-9b33-4e43e52dda95"
      },
      "source": [
        "print(x*y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.7583, 0.4706, 0.0484],\n",
            "        [1.2583, 0.7362, 0.2400],\n",
            "        [0.0311, 0.1932, 1.8488]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naidinMb5oxT"
      },
      "source": [
        "###Matrix multiplication"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtN0vws3KlbS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77d72fd1-c9d0-4969-f2ef-74f247aea95d"
      },
      "source": [
        "z = torch.matmul(x,y[:,0])\n",
        "print(z)\n",
        "z.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.5724, 2.4641, 0.9160])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7qePwsG5zrc"
      },
      "source": [
        "###Reshaping tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKJcA3gxR1ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47dfc407-304f-4dfb-9bbf-e758a94e03a2"
      },
      "source": [
        "x = torch.rand(5,6)\n",
        "print(\"Size of x :\\n\",x.size())\n",
        "print(\"x:\\n\",x)\n",
        "y = x.view(30)\n",
        "print(\"Size of y :\\n\",y.size())\n",
        "print(\"y:\\n\",y)\n",
        "y = x.view(3,10)\n",
        "print(\"Size of y :\\n\",y.size())\n",
        "print(\"y:\\n\",y)\n",
        "\n",
        "z = x.view(15,-1)\n",
        "print(\"Size of z :\\n\",z.size())\n",
        "print(\"z:\\n\",z)\n",
        "\n",
        "z = x.view(-1,15)\n",
        "print(\"Size of z :\\n\",z.size())\n",
        "print(\"z:\\n\",z)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of x :\n",
            " torch.Size([5, 6])\n",
            "x:\n",
            " tensor([[0.9707, 0.0126, 0.8908, 0.5658, 0.0661, 0.7999],\n",
            "        [0.4487, 0.3790, 0.6069, 0.3659, 0.6588, 0.8794],\n",
            "        [0.9515, 0.5225, 0.7153, 0.5951, 0.1788, 0.1032],\n",
            "        [0.2507, 0.5446, 0.0125, 0.2736, 0.2900, 0.1199],\n",
            "        [0.1821, 0.9479, 0.3811, 0.0064, 0.1512, 0.4417]])\n",
            "Size of y :\n",
            " torch.Size([30])\n",
            "y:\n",
            " tensor([0.9707, 0.0126, 0.8908, 0.5658, 0.0661, 0.7999, 0.4487, 0.3790, 0.6069,\n",
            "        0.3659, 0.6588, 0.8794, 0.9515, 0.5225, 0.7153, 0.5951, 0.1788, 0.1032,\n",
            "        0.2507, 0.5446, 0.0125, 0.2736, 0.2900, 0.1199, 0.1821, 0.9479, 0.3811,\n",
            "        0.0064, 0.1512, 0.4417])\n",
            "Size of y :\n",
            " torch.Size([3, 10])\n",
            "y:\n",
            " tensor([[0.9707, 0.0126, 0.8908, 0.5658, 0.0661, 0.7999, 0.4487, 0.3790, 0.6069,\n",
            "         0.3659],\n",
            "        [0.6588, 0.8794, 0.9515, 0.5225, 0.7153, 0.5951, 0.1788, 0.1032, 0.2507,\n",
            "         0.5446],\n",
            "        [0.0125, 0.2736, 0.2900, 0.1199, 0.1821, 0.9479, 0.3811, 0.0064, 0.1512,\n",
            "         0.4417]])\n",
            "Size of z :\n",
            " torch.Size([15, 2])\n",
            "z:\n",
            " tensor([[0.9707, 0.0126],\n",
            "        [0.8908, 0.5658],\n",
            "        [0.0661, 0.7999],\n",
            "        [0.4487, 0.3790],\n",
            "        [0.6069, 0.3659],\n",
            "        [0.6588, 0.8794],\n",
            "        [0.9515, 0.5225],\n",
            "        [0.7153, 0.5951],\n",
            "        [0.1788, 0.1032],\n",
            "        [0.2507, 0.5446],\n",
            "        [0.0125, 0.2736],\n",
            "        [0.2900, 0.1199],\n",
            "        [0.1821, 0.9479],\n",
            "        [0.3811, 0.0064],\n",
            "        [0.1512, 0.4417]])\n",
            "Size of z :\n",
            " torch.Size([2, 15])\n",
            "z:\n",
            " tensor([[0.9707, 0.0126, 0.8908, 0.5658, 0.0661, 0.7999, 0.4487, 0.3790, 0.6069,\n",
            "         0.3659, 0.6588, 0.8794, 0.9515, 0.5225, 0.7153],\n",
            "        [0.5951, 0.1788, 0.1032, 0.2507, 0.5446, 0.0125, 0.2736, 0.2900, 0.1199,\n",
            "         0.1821, 0.9479, 0.3811, 0.0064, 0.1512, 0.4417]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Q8u8Ybl6aTE"
      },
      "source": [
        "###Generating Numbers in Sequence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKZfbRSmTrKZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d201e327-1721-417f-aa07-26771480f478"
      },
      "source": [
        "x = torch.arange(9)\n",
        "print(x)\n",
        "x = x.view(3,3)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [6, 7, 8]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kn3gIaFa6mgN"
      },
      "source": [
        "###Concatenating two tensors at a given dimension"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jq3lfDaV6ly8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f28d7dc-bcce-41ce-bb0e-54fc433991f9"
      },
      "source": [
        "print(x)\n",
        "print(torch.cat((x,x),dim=0))\n",
        "print(torch.cat((x,x),dim=1))\n",
        "print(x+x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [6, 7, 8]])\n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [6, 7, 8],\n",
            "        [0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [6, 7, 8]])\n",
            "tensor([[0, 1, 2, 0, 1, 2],\n",
            "        [3, 4, 5, 3, 4, 5],\n",
            "        [6, 7, 8, 6, 7, 8]])\n",
            "tensor([[ 0,  2,  4],\n",
            "        [ 6,  8, 10],\n",
            "        [12, 14, 16]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wztx_uOL6s4_"
      },
      "source": [
        "###Reducing the redundant dimension by squeeze operation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bpPpJsVVPZj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afa7f32b-9546-4e63-f91d-d7c35c50b806"
      },
      "source": [
        "x1= torch.rand(1,5)\n",
        "print(\"size of x1 squeezing:\\n\",x1.size())\n",
        "print(x1)\n",
        "x1 = x1.squeeze()\n",
        "print(\"size of x1 after squeezing:\\n\", x1.size())\n",
        "print(x1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size of x1 squeezing:\n",
            " torch.Size([1, 5])\n",
            "tensor([[0.5327, 0.3877, 0.8448, 0.6483, 0.3719]])\n",
            "size of x1 after squeezing:\n",
            " torch.Size([5])\n",
            "tensor([0.5327, 0.3877, 0.8448, 0.6483, 0.3719])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUSXmKCTgzpa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4175a353-2233-4c0b-d7fa-5b3481193350"
      },
      "source": [
        "x1 = torch.rand(1,1,5)\n",
        "print(\"size of x1 before squeezing:\\n\", x1.size())\n",
        "print(x1)\n",
        "x1 = x1.squeeze()\n",
        "print(\"size of x1 after squeezing:\\n\", x1.size())\n",
        "print(x1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size of x1 before squeezing:\n",
            " torch.Size([1, 1, 5])\n",
            "tensor([[[0.0103, 0.5598, 0.0166, 0.7481, 0.0359]]])\n",
            "size of x1 after squeezing:\n",
            " torch.Size([5])\n",
            "tensor([0.0103, 0.5598, 0.0166, 0.7481, 0.0359])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKD-tFDYe-lz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2c870ee-e24b-472e-8a83-02dc2db012a0"
      },
      "source": [
        "x2 = torch.rand(3,1,4,1,5)\n",
        "print(\"size of x2 before squeezing:\\n\", x2.size())\n",
        "#print(x2)\n",
        "x2 = x2.squeeze()\n",
        "print(\"size of x2 after squeezing:\\n\", x2.size())\n",
        "x2 = x2.squeeze()\n",
        "print(\"size of x2 after squeezing:\\n\", x2.size())\n",
        "#print(x2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size of x2 before squeezing:\n",
            " torch.Size([3, 1, 4, 1, 5])\n",
            "size of x2 after squeezing:\n",
            " torch.Size([3, 4, 5])\n",
            "size of x2 after squeezing:\n",
            " torch.Size([3, 4, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-dy0VY077gG"
      },
      "source": [
        "###Extending the dimension by unsqueeze operation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qt6GvYtJWtSp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47024242-1cc8-4de5-8d18-b1fc181251df"
      },
      "source": [
        "x = torch.rand(3,4,5,6)\n",
        "print(x.size())\n",
        "print(x.unsqueeze(dim=2).size())\n",
        "print(x.unsqueeze(dim=3).size())\n",
        "print(x.unsqueeze(dim=4).size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 4, 5, 6])\n",
            "torch.Size([3, 4, 1, 5, 6])\n",
            "torch.Size([3, 4, 5, 1, 6])\n",
            "torch.Size([3, 4, 5, 6, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uE2GJRkBasOw"
      },
      "source": [
        "###Numpy Bridge\n",
        "####Converting a numpy array to torch tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26-U02yFZGT0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "9c98735e-f3b5-445a-e439-06f586588bd9"
      },
      "source": [
        "x = np.array([[1.0,2],[3,4]])\n",
        "print(type(x))\n",
        "y = torch.from_numpy(x)\n",
        "print(y)\n",
        "y.type()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "tensor([[1., 2.],\n",
            "        [3., 4.]], dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'torch.DoubleTensor'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsAxO1Sj_yL0"
      },
      "source": [
        "####Converting a torch tensor to numpy array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ei-KpF1MZLm9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e20ad04b-d272-4f1c-c1d0-f0057f43e00b"
      },
      "source": [
        "z = y.numpy()\n",
        "z.dtype"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float64')"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNJZQcnddMoC"
      },
      "source": [
        "**CUDA Tensors**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7gXIIyjAXqO"
      },
      "source": [
        "####Checking the availability of CUDA/GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wqlDh-VbFWP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f956c769-9932-489f-fdea-3bdc82afdf4c"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkIDqwYPdZpe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e47c4a9-754d-4b2a-83ec-690888326520"
      },
      "source": [
        "# Linux bash command to print the status of nvidia gpu (memory and processes)\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Aug 18 10:32:32 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P8              11W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXpbPJ0dAnze"
      },
      "source": [
        "####Defining the device object (cpu/gpu)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0heiVkdBdiAe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "1f853194-4526-46eb-e495-cfdd444f553b"
      },
      "source": [
        "device = torch.device(\"cuda\")\n",
        "x = torch.rand(3,3)\n",
        "print(x)\n",
        "x.type()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.7483, 0.3773, 0.2417],\n",
            "        [0.2552, 0.0043, 0.6945],\n",
            "        [0.4298, 0.0839, 0.3604]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'torch.FloatTensor'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xR2cjesYAsYW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "97c206ee-562d-417a-8594-3b0bef47b06f"
      },
      "source": [
        "x = x.to(device)\n",
        "x.type()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'torch.cuda.FloatTensor'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzgU1Lw2A2qc"
      },
      "source": [
        "\n",
        "###Transferring the tensor to the respective device (here cpu->gpu)\n",
        "####Transferring the tensor from gpu->cpu\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9VMq1zJd-N9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "925ab6df-36a3-46a9-d224-b49802407b96"
      },
      "source": [
        "# Transferring the tensor from gpu->cpu\n",
        "device_cpu = torch.device(\"cpu\")\n",
        "x = x.to(device_cpu)\n",
        "x.type()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'torch.FloatTensor'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3> Building Block #2 : Computation Graph</h3>\n",
        "    \n",
        "   Computation graphs lie at the heart of the way modern deep learning networks work, and PyTorch is no exception. Let us first get the hang of what they are.\n",
        "   \n",
        "Now, why should we create such a graph when we can sequentially execute operations required to compute the output?\n",
        "\n",
        "Imagine, what were to happen, if you didn’t merely have to calculate the output but also train the network. You’ll have to compute the gradients for all the weights labelled by purple nodes. That would require you to figure your way around chain rule, and then update the weights.\n",
        "\n",
        "<b>The computation graph is simply a data structure that allows you to efficiently apply the chain rule to compute gradients for all of your parameters.</b>\n",
        "\n",
        "<h3> Building Block #3 : Variables</h3>\n",
        "\n",
        "The Variable, just like a Tensor is a class that is used to hold data. It differs, however, in the way it’s meant to be used. <b>Variables are specifically tailored to hold values which change during training of a neural network, i.e. the learnable paramaters of our network.</b> Tensors on the other hand are used to store values that are not to be learned. For example, a Tensor maybe used to store the values of the loss generated by each example.\n",
        "\n",
        "A Variable class wraps a tensor. You can access this tensor by calling <b>.data</b> attribute of a Variable.\n",
        "\n",
        "The Variable also stores the gradient of a scalar quantity (say, loss) with respect to the parameter it holds. This gradient can be accessed by calling the <b>.grad</b> attribute. This is basically the gradient computed up to this particular node, and the gradient of the ever subsequent node, can be computed by multiplying the edge weight with the gradient computed at the node just before it.\n",
        "\n",
        "The third attribute a Variable holds is a <b>grad_fn</b>, a Function object which created the variable.\n",
        "\n",
        "While training neural networks, there are two steps: the forward pass, and the backward pass. Normally, if you were to implement it using python functions, you will have to define two functions. One, to compute the output during forward pass, and another, to compute the gradient to be propagated.\n",
        "\n",
        "<b>PyTorch abstracts the need to write two separate functions (for forward, and for backward pass), into two member of functions of a single class called torch.autograd.Function.</b>\n",
        "\n",
        "PyTorch combines Variables and functions to create a computation graph."
      ],
      "metadata": {
        "id": "z9trmeXjVXH-"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-nqAVFQjjq7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a871cd02-8ae1-4e16-a5e8-c50916fedd94"
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "N=64\n",
        "D_in=1000\n",
        "H=100\n",
        "D_out=1\n",
        "x = Variable(torch.randn(N, D_in), requires_grad=False)\n",
        "y = Variable(torch.randn(N, D_out), requires_grad=False)\n",
        "w1 = Variable(torch.randn(D_in,H), requires_grad=True)\n",
        "b1 = Variable(torch.randn(H), requires_grad=True)\n",
        "w2 = Variable(torch.randn(H, D_out), requires_grad=True)\n",
        "b2 = Variable(torch.randn(D_out), requires_grad=True)\n",
        "\n",
        "learning_rate = 1e-6\n",
        "for t in range(500):\n",
        "    y_pred = (x.mm(w1)+b1).clamp(min=0).mm(w2)+b2\n",
        "    loss = (y_pred-y).pow(2).sum()\n",
        "    loss.backward()\n",
        "    w1.data -= learning_rate*w1.grad\n",
        "    w2.data -= learning_rate*w2.grad\n",
        "    b1.data -= learning_rate*b1.grad\n",
        "    b2.data -= learning_rate*b2.grad\n",
        "    w1.grad.data.zero_()\n",
        "    w2.grad.data.zero_()\n",
        "    b1.grad.data.zero_()\n",
        "    b2.grad.data.zero_()\n",
        "    if t%10==0:\n",
        "      print(loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2350935.5000, grad_fn=<SumBackward0>)\n",
            "tensor(7613089., grad_fn=<SumBackward0>)\n",
            "tensor(1627877., grad_fn=<SumBackward0>)\n",
            "tensor(8939.0469, grad_fn=<SumBackward0>)\n",
            "tensor(818.5197, grad_fn=<SumBackward0>)\n",
            "tensor(229.6561, grad_fn=<SumBackward0>)\n",
            "tensor(68.0868, grad_fn=<SumBackward0>)\n",
            "tensor(20.6655, grad_fn=<SumBackward0>)\n",
            "tensor(6.3920, grad_fn=<SumBackward0>)\n",
            "tensor(2.0080, grad_fn=<SumBackward0>)\n",
            "tensor(0.6394, grad_fn=<SumBackward0>)\n",
            "tensor(0.2060, grad_fn=<SumBackward0>)\n",
            "tensor(0.0671, grad_fn=<SumBackward0>)\n",
            "tensor(0.0220, grad_fn=<SumBackward0>)\n",
            "tensor(0.0073, grad_fn=<SumBackward0>)\n",
            "tensor(0.0025, grad_fn=<SumBackward0>)\n",
            "tensor(0.0009, grad_fn=<SumBackward0>)\n",
            "tensor(0.0004, grad_fn=<SumBackward0>)\n",
            "tensor(0.0002, grad_fn=<SumBackward0>)\n",
            "tensor(9.1850e-05, grad_fn=<SumBackward0>)\n",
            "tensor(5.4582e-05, grad_fn=<SumBackward0>)\n",
            "tensor(3.4742e-05, grad_fn=<SumBackward0>)\n",
            "tensor(2.3655e-05, grad_fn=<SumBackward0>)\n",
            "tensor(1.6587e-05, grad_fn=<SumBackward0>)\n",
            "tensor(1.2095e-05, grad_fn=<SumBackward0>)\n",
            "tensor(9.1040e-06, grad_fn=<SumBackward0>)\n",
            "tensor(7.1586e-06, grad_fn=<SumBackward0>)\n",
            "tensor(5.5932e-06, grad_fn=<SumBackward0>)\n",
            "tensor(4.5892e-06, grad_fn=<SumBackward0>)\n",
            "tensor(3.7702e-06, grad_fn=<SumBackward0>)\n",
            "tensor(3.2220e-06, grad_fn=<SumBackward0>)\n",
            "tensor(2.8485e-06, grad_fn=<SumBackward0>)\n",
            "tensor(2.4359e-06, grad_fn=<SumBackward0>)\n",
            "tensor(2.1744e-06, grad_fn=<SumBackward0>)\n",
            "tensor(1.9786e-06, grad_fn=<SumBackward0>)\n",
            "tensor(1.8483e-06, grad_fn=<SumBackward0>)\n",
            "tensor(1.6792e-06, grad_fn=<SumBackward0>)\n",
            "tensor(1.5536e-06, grad_fn=<SumBackward0>)\n",
            "tensor(1.4411e-06, grad_fn=<SumBackward0>)\n",
            "tensor(1.3284e-06, grad_fn=<SumBackward0>)\n",
            "tensor(1.2510e-06, grad_fn=<SumBackward0>)\n",
            "tensor(1.1623e-06, grad_fn=<SumBackward0>)\n",
            "tensor(1.1224e-06, grad_fn=<SumBackward0>)\n",
            "tensor(1.0553e-06, grad_fn=<SumBackward0>)\n",
            "tensor(9.9813e-07, grad_fn=<SumBackward0>)\n",
            "tensor(9.3161e-07, grad_fn=<SumBackward0>)\n",
            "tensor(9.0523e-07, grad_fn=<SumBackward0>)\n",
            "tensor(8.6098e-07, grad_fn=<SumBackward0>)\n",
            "tensor(7.8765e-07, grad_fn=<SumBackward0>)\n",
            "tensor(7.4489e-07, grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(w1.size())\n",
        "print(w2.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShURRFCYJ74w",
        "outputId": "cddbf18d-e320-4014-b488-c6f2886da224"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 100])\n",
            "torch.Size([100, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMJoTHg8EJKs",
        "outputId": "5b112dae-2579-4e14-bcc0-1db75bf733d2"
      },
      "source": [
        "w1.ndim"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    }
  ]
}